{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMxzuoI3k7rq"
      },
      "source": [
        "# Transformer Architecture\n",
        "\n",
        "![Transformer](https://miro.medium.com/v2/resize:fit:760/1*2vyKzFlzIHfSmOU_lnQE4A.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_m1kcFZmFr-"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZTQBidDAg5u",
        "outputId": "652dfc61-f1cf-40ca-d8e6-f357de9e45d6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-3-17e3dd6347dd>:2: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  F.softmax(k)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([nan, nan, nan, nan])"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "k = torch.tensor([  float(\" -inf\"),   float(\" -inf\"), float(\" -inf\"), float(\" -inf\")])\n",
        "F.softmax(k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "hKiyH5cJnubh",
        "outputId": "d4e4b755-37f5-40f6-d282-2a05f09bd9d2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "         [0.6247, 0.3753, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "         [0.2739, 0.1008, 0.6253,  ..., 0.0000, 0.0000, 0.0000],\n",
              "         ...,\n",
              "         [0.0757, 0.2967, 0.1330,  ..., 0.0000, 0.0000, 0.0000],\n",
              "         [0.1622, 0.0216, 0.3364,  ..., 0.0000, 0.0000, 0.0000],\n",
              "         [0.0973, 0.1536, 0.0484,  ..., 0.0000, 0.0000, 0.0000]],\n",
              "\n",
              "        [[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "         [0.9084, 0.0916, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "         [0.3221, 0.1061, 0.5718,  ..., 0.0000, 0.0000, 0.0000],\n",
              "         ...,\n",
              "         [0.0555, 0.1129, 0.2225,  ..., 0.0000, 0.0000, 0.0000],\n",
              "         [0.0434, 0.0856, 0.0370,  ..., 0.0000, 0.0000, 0.0000],\n",
              "         [0.0826, 0.4050, 0.0066,  ..., 0.0000, 0.0000, 0.0000]],\n",
              "\n",
              "        [[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "         [0.4215, 0.5785, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "         [0.3405, 0.5131, 0.1464,  ..., 0.0000, 0.0000, 0.0000],\n",
              "         ...,\n",
              "         [0.0257, 0.0773, 0.0488,  ..., 0.0000, 0.0000, 0.0000],\n",
              "         [0.1592, 0.1103, 0.0364,  ..., 0.0000, 0.0000, 0.0000],\n",
              "         [0.0246, 0.0304, 0.1949,  ..., 0.0000, 0.0000, 0.0000]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "         [0.3846, 0.6154, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "         [0.1004, 0.1183, 0.7813,  ..., 0.0000, 0.0000, 0.0000],\n",
              "         ...,\n",
              "         [0.0384, 0.0156, 0.0510,  ..., 0.0000, 0.0000, 0.0000],\n",
              "         [0.0325, 0.1381, 0.1088,  ..., 0.0000, 0.0000, 0.0000],\n",
              "         [0.0608, 0.1496, 0.0832,  ..., 0.0000, 0.0000, 0.0000]],\n",
              "\n",
              "        [[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "         [0.8560, 0.1440, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "         [0.1356, 0.1595, 0.7049,  ..., 0.0000, 0.0000, 0.0000],\n",
              "         ...,\n",
              "         [0.1524, 0.3258, 0.0128,  ..., 0.0000, 0.0000, 0.0000],\n",
              "         [0.0362, 0.1166, 0.0462,  ..., 0.0000, 0.0000, 0.0000],\n",
              "         [0.1160, 0.1440, 0.0537,  ..., 0.0000, 0.0000, 0.0000]],\n",
              "\n",
              "        [[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "         [0.0795, 0.9205, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "         [0.1855, 0.5587, 0.2557,  ..., 0.0000, 0.0000, 0.0000],\n",
              "         ...,\n",
              "         [0.1720, 0.0577, 0.0301,  ..., 0.0000, 0.0000, 0.0000],\n",
              "         [0.1133, 0.3428, 0.0257,  ..., 0.0000, 0.0000, 0.0000],\n",
              "         [0.0610, 0.0414, 0.2662,  ..., 0.0000, 0.0000, 0.0000]]])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "k = torch.randn(32, 10, 512)\n",
        "k.view(32, 10, 8, -1).shape\n",
        "k = torch.tril(k)\n",
        "k = k.masked_fill(k==0, float('-Inf'))\n",
        "F.softmax(k, dim=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UOK4ZgAk0y6"
      },
      "source": [
        "## Positional Encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYbRpQo0mFZy"
      },
      "source": [
        "<img src=\"https://miro.medium.com/v2/resize:fit:640/format:webp/1*m2SB7rpbHdL9UGCFySE40w.png\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zC0ts6HTpG1v"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "  def __init__(self, seq_len, embed_dim):\n",
        "    super(PositionalEncoding, self).__init__()\n",
        "\n",
        "    pe = torch.zeros(seq_len, embed_dim)\n",
        "    position = torch.arange(0, seq_len, dtype=torch.float).unsqueeze(1)\n",
        "\n",
        "    i = torch.exp(torch.arange(0, embed_dim, 2).float() * (-math.log(10000.0) / embed_dim))\n",
        "    pe[:, 0::2] = torch.sin(position * i)\n",
        "    pe[:, 1::2] = torch.cos(position * i)\n",
        "\n",
        "    pe = pe.unsqueeze(0)\n",
        "\n",
        "    self.register_buffer('pe', pe)\n",
        "\n",
        "  def forward(self, x):\n",
        "    self.pe = self.pe.to(x.device)\n",
        "    return x + self.pe[:, :x.size(1), :]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aANCXrz1i49u",
        "outputId": "092e5102-b863-4a92-e741-509b24c0eaf4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([32, 10, 2])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "p = torch.randn(32, 10, 2)\n",
        "pe = PositionalEncoding(10, 2)\n",
        "pe(p).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjS1T648HZQ8",
        "outputId": "f4268520-cbf9-4b5a-981e-db2a57db5f3d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[ 0.0000,  1.0000],\n",
              "         [ 0.8415,  0.5403],\n",
              "         [ 0.9093, -0.4161],\n",
              "         [ 0.1411, -0.9900],\n",
              "         [-0.7568, -0.6536],\n",
              "         [-0.9589,  0.2837],\n",
              "         [-0.2794,  0.9602],\n",
              "         [ 0.6570,  0.7539],\n",
              "         [ 0.9894, -0.1455],\n",
              "         [ 0.4121, -0.9111]]])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "p = torch.randn(1, 10, 2)\n",
        "pe = PositionalEncoding(10, 2)\n",
        "pe(p)- p"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weex-8vTMH7K"
      },
      "source": [
        "## 1. MultiHead Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RtN0046nmNsS"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self, embed_dim, n_heads):\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "\n",
        "    self.embed_dim = embed_dim\n",
        "    self.n_heads = n_heads\n",
        "    self.single_head_dim = embed_dim // n_heads\n",
        "\n",
        "    self.query_m = nn.Linear(embed_dim, embed_dim, bias=False)\n",
        "    self.key_m = nn.Linear(embed_dim, embed_dim, bias=False)\n",
        "    self.value_m = nn.Linear(embed_dim, embed_dim, bias=False)\n",
        "\n",
        "    self.output = nn.Linear(embed_dim, embed_dim)\n",
        "\n",
        "  def forward(self, query, key, value, mask=None):\n",
        "    batch_size = key.shape[0]\n",
        "    seq_len = key.shape[1]\n",
        "    query_seq_len = query.shape[1]\n",
        "\n",
        "    q = self.query_m(query) # (batch_size, seq_len, embed_dim)\n",
        "    k = self.key_m(key)     # (batch_size, seq_len, embed_dim)\n",
        "    v = self.value_m(value) # (batch_size, seq_len, embed_dim)\n",
        "    # print(f\"Shapes of query, key, value are {q.shape, k.shape, v.shape}\")\n",
        "\n",
        "    q = q.view(batch_size, query_seq_len, self.n_heads, self.single_head_dim) # (batch_size, query_seq_len, n_heads, single_head_dim)\n",
        "    k = k.view(batch_size, seq_len, self.n_heads, self.single_head_dim) # (batch_size, seq_len, n_heads, single_head_dim)\n",
        "    v = v.view(batch_size, seq_len, self.n_heads, self.single_head_dim) # (batch_size, seq_len, n_heads, single_head_dim)\n",
        "    # print(f\"Shapes of q, k, v are {q.shape, k.shape, v.shape}\")\n",
        "\n",
        "    q = q.transpose(1, 2) # (batch_size, n_heads, seq_len, single_head_dim)\n",
        "    k = k.transpose(1, 2) # (batch_size, n_heads, seq_len, single_head_dim)\n",
        "    v = v.transpose(1, 2) # (batch_size, n_heads, seq_len, single_head_dim)\n",
        "    # print(f\"Shapes of q, k, v are {q.shape, k.shape, v.shape}\")\n",
        "\n",
        "    qk = torch.matmul(q, k.transpose(-1, -2)) # (batch_size, n_heads, seq_len, seq_len)\n",
        "    # print(f\"Shape of qk is{qk.shape}\")\n",
        "    # print(f\"Before masking {qk}\")\n",
        "\n",
        "    if mask is not None:\n",
        "      qk = qk.masked_fill(mask == 0, -1e20)\n",
        "      # qk = qk.masked_fill(mask == 0, float(\"-inf\"))\n",
        "    # print(f\"After masking {qk}\")\n",
        "\n",
        "    qk = qk/(self.single_head_dim ** 0.5)\n",
        "\n",
        "    attn_scores = F.softmax(qk, dim=-1) # (batch_size, n_heads, seq_len, seq_len)\n",
        "    # print(f\"After softmax {attn_scores}\")\n",
        "\n",
        "    attn_scores = torch.matmul(attn_scores, v) # (batch_size, n_heads, seq_len, single_head_dim)\n",
        "    # print(f\"Shape of attention scores is{att_scores.shape}\")\n",
        "    # print(f\"Attention {attn_scores}\")\n",
        "\n",
        "    out = attn_scores.transpose(1, 2).contiguous() # (batch_size, seq_len, n_heads, single_head_dim)\n",
        "    out = out.view(batch_size, query_seq_len, self.n_heads*self.single_head_dim) # (batch_size, seq_len, embed_dim)\n",
        "\n",
        "    out = self.output(out)  # (batch_size, seq_len, embed_dim)\n",
        "\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZph0oYUQMTH",
        "outputId": "be4b6518-1aff-4de9-e042-35fe7642dc08"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MultiHeadAttention(\n",
              "  (query_m): Linear(in_features=512, out_features=512, bias=False)\n",
              "  (key_m): Linear(in_features=512, out_features=512, bias=False)\n",
              "  (value_m): Linear(in_features=512, out_features=512, bias=False)\n",
              "  (output): Linear(in_features=512, out_features=512, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "m = MultiHeadAttention(512, 8)\n",
        "m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHGrlroWRlxg",
        "outputId": "c78d28a0-2074-4fb5-9595-2125531dd8ba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([32, 10, 512])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "q = torch.randn(32, 10, 512)\n",
        "v = torch.randn(32, 10, 512)\n",
        "k = torch.randn(32, 10, 512)\n",
        "m(q, v , k).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWVNIhATRsbf"
      },
      "source": [
        "## 2. Encoder\n",
        "\n",
        "<img src=\"https://www.researchgate.net/profile/Ehsan-Amjadian/publication/352239001/figure/fig1/AS:1033334390013952@1623377525434/Detailed-view-of-a-transformer-encoder-block-It-first-passes-the-input-through-an.jpg\" height=\"480\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jYXli4uCYu2F"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "  def __init__(self, embed_dim, n_heads, hidden_factor=4, dropout=0.1):\n",
        "    super(EncoderLayer, self).__init__()\n",
        "\n",
        "    self.self_attn = MultiHeadAttention(embed_dim, n_heads)\n",
        "    self.feed_fwd = nn.Sequential(\n",
        "        nn.Linear(embed_dim, embed_dim*hidden_factor),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(dropout),\n",
        "        nn.Linear(embed_dim*hidden_factor, embed_dim)\n",
        "    )\n",
        "    self.norm1 = nn.LayerNorm(embed_dim)\n",
        "    self.norm2 = nn.LayerNorm(embed_dim)\n",
        "    self.drop = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, x, mask=None):\n",
        "    attn = self.self_attn(x, x, x, mask=None) # (batch_size, seq_len, embed_dim)\n",
        "    x = x + self.drop(attn) # attentionresidual\n",
        "    x = self.norm1(x) # attention residual normalization\n",
        "\n",
        "    feed_forward = self.feed_fwd(x)\n",
        "    # (batch_size, seq_len, embed_dim) -> (batch_size, seq_len, embed_dim*hidden_factor) -> (batch_size, seq_len, embed_dim)\n",
        "    x = x + self.drop(feed_forward) # feed forward residual\n",
        "    x = self.norm2(x) # feed forward residual normalization\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTpRInILkIVS"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, input_vocab, embed_dim, seq_len, n_heads=8, num_layers=2, hidden_factor=4, dropout=0.1):\n",
        "    super(Encoder, self).__init__()\n",
        "\n",
        "    self.embedding = nn.Embedding(input_vocab, embed_dim)\n",
        "    self.pe = PositionalEncoding(seq_len, embed_dim)\n",
        "    self.layers = nn.ModuleList([EncoderLayer(embed_dim, n_heads, hidden_factor, dropout) for _ in range(num_layers)])\n",
        "    self.drop = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, src, mask=None):\n",
        "    x = self.embedding(src) # (batch_size, seq_len) -> (batch_size, seq_len, embed_dim)\n",
        "    x = self.pe(x) # (batch_size, seq_len, embed_dim)\n",
        "    x = self.drop(x)\n",
        "\n",
        "    for layer in self.layers:\n",
        "      x = layer(x, mask)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGIP3UUTq8gM",
        "outputId": "58bc496e-2265-4270-8a7f-9b3567280d70"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Encoder(\n",
              "  (embedding): Embedding(5500, 512)\n",
              "  (pe): PositionalEncoding()\n",
              "  (layers): ModuleList(\n",
              "    (0-1): 2 x EncoderLayer(\n",
              "      (self_attn): MultiHeadAttention(\n",
              "        (query_m): Linear(in_features=512, out_features=512, bias=False)\n",
              "        (key_m): Linear(in_features=512, out_features=512, bias=False)\n",
              "        (value_m): Linear(in_features=512, out_features=512, bias=False)\n",
              "        (output): Linear(in_features=512, out_features=512, bias=True)\n",
              "      )\n",
              "      (feed_fwd): Sequential(\n",
              "        (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "        (1): ReLU()\n",
              "        (2): Dropout(p=0.1, inplace=False)\n",
              "        (3): Linear(in_features=2048, out_features=512, bias=True)\n",
              "      )\n",
              "      (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (drop): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (drop): Dropout(p=0.1, inplace=False)\n",
              ")"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "enc = Encoder(5500, 512, 10, 8, 2, 4, 0.1)\n",
        "enc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fk-XMJVhrRyk",
        "outputId": "d746e311-69b2-418d-a9e0-d48ae38c69df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([32, 10, 512])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "s = torch.randint(0, 5500, (32, 10))\n",
        "so = enc(s, None)\n",
        "so.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmya4JrifcQD"
      },
      "source": [
        "## 2. Decoder\n",
        "\n",
        "<img src=\"https://discuss.pytorch.org/uploads/default/optimized/3X/8/e/8e5d039948b8970e6b25395cb207febc82ba320a_2_177x500.png\" height=\"480\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ceT4x3XgSpi"
      },
      "outputs": [],
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "  def __init__(self, embed_dim, n_heads, hidden_factor=4, dropout=0.1):\n",
        "    super(DecoderLayer, self).__init__()\n",
        "\n",
        "    self.self_attn = MultiHeadAttention(embed_dim, n_heads)\n",
        "    self.cross_attn = MultiHeadAttention(embed_dim, n_heads) # Encoder-Decoder Attention\n",
        "    self.feed_fwd = nn.Sequential(\n",
        "        nn.Linear(embed_dim, embed_dim*hidden_factor),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(dropout),\n",
        "        nn.Linear(embed_dim*hidden_factor, embed_dim)\n",
        "    )\n",
        "    self.norm1 = nn.LayerNorm(embed_dim)\n",
        "    self.norm2 = nn.LayerNorm(embed_dim)\n",
        "    self.norm3 = nn.LayerNorm(embed_dim)\n",
        "    self.drop = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, x, enc_output, src_mask=None, tgt_mask=None):\n",
        "    self_attention = self.self_attn(x, x, x, tgt_mask)\n",
        "    x = x + self.drop(self_attention) # residual\n",
        "    x = self.norm1(x) # normalization\n",
        "\n",
        "    cross_attention = self.cross_attn(x, enc_output, enc_output)\n",
        "    x = x + self.drop(cross_attention) # residual\n",
        "    x = self.norm2(x)\n",
        "\n",
        "    feed_forward = self.feed_fwd(x)\n",
        "    x = x + self.drop(feed_forward)\n",
        "    x = self.norm3(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dz9WFomlEoJ8"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self, output_vocab, embed_dim, seq_len, n_heads=8, num_layers=2, hidden_factor=4, dropout=0.1):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.embedding = nn.Embedding(output_vocab, embed_dim)\n",
        "    self.pe = PositionalEncoding(seq_len , embed_dim)\n",
        "    self.layers = nn.ModuleList([DecoderLayer(embed_dim, n_heads, hidden_factor, dropout) for _ in range(num_layers)])\n",
        "    self.output = nn.Linear(embed_dim , output_vocab)\n",
        "    self.drop = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, tgt, enc_output, src_mask=None, tgt_mask=None):\n",
        "    x = self.embedding(tgt)\n",
        "    x = self.pe(x)\n",
        "    x = self.drop(x)\n",
        "\n",
        "    for layer in self.layers:\n",
        "      x = layer(x, enc_output, src_mask, tgt_mask)\n",
        "\n",
        "    x = self.output(x)\n",
        "    x = F.softmax(x, dim=-1)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sn6OMIYgIKyZ",
        "outputId": "ffd60993-32df-40ca-8039-0d07b74d817b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Decoder(\n",
              "  (embedding): Embedding(5500, 512)\n",
              "  (pe): PositionalEncoding()\n",
              "  (layers): ModuleList(\n",
              "    (0-1): 2 x DecoderLayer(\n",
              "      (self_attn): MultiHeadAttention(\n",
              "        (query_m): Linear(in_features=512, out_features=512, bias=False)\n",
              "        (key_m): Linear(in_features=512, out_features=512, bias=False)\n",
              "        (value_m): Linear(in_features=512, out_features=512, bias=False)\n",
              "        (output): Linear(in_features=512, out_features=512, bias=True)\n",
              "      )\n",
              "      (cross_attn): MultiHeadAttention(\n",
              "        (query_m): Linear(in_features=512, out_features=512, bias=False)\n",
              "        (key_m): Linear(in_features=512, out_features=512, bias=False)\n",
              "        (value_m): Linear(in_features=512, out_features=512, bias=False)\n",
              "        (output): Linear(in_features=512, out_features=512, bias=True)\n",
              "      )\n",
              "      (feed_fwd): Sequential(\n",
              "        (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "        (1): ReLU()\n",
              "        (2): Dropout(p=0.1, inplace=False)\n",
              "        (3): Linear(in_features=2048, out_features=512, bias=True)\n",
              "      )\n",
              "      (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (drop): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (output): Linear(in_features=512, out_features=5500, bias=True)\n",
              "  (drop): Dropout(p=0.1, inplace=False)\n",
              ")"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dec = Decoder(5500, 512, 10, 8, 2, 4, 0.1)\n",
        "dec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8EJgHwlHyut",
        "outputId": "733f3703-ca56-4db2-dfbd-06b92157e2a2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([32, 10, 5500])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t = torch.randint(0, 5500, (32, 10))\n",
        "F.softmax(dec(t, so, None, None), dim=-1).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jOnLUtEhoz4"
      },
      "source": [
        "### Masking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfKid0SYh2mv"
      },
      "outputs": [],
      "source": [
        "def create_mask(src, tgt, pad_token):\n",
        "  src_mask = (src != pad_token).unsqueeze(-2)\n",
        "  tgt_mask = (tgt != pad_token).unsqueeze(-2)\n",
        "\n",
        "  seq_len = tgt.size(1)\n",
        "  mask = torch.tril(torch.ones(1, seq_len, seq_len)).bool()\n",
        "\n",
        "  tgt_mask = tgt_mask & mask\n",
        "  tgt_mask = tgt_mask.unsqueeze(1)\n",
        "  src_mask = src_mask.unsqueeze(1)\n",
        "\n",
        "  return src_mask, tgt_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubkSmnOsikGf",
        "outputId": "7cc31690-c233-432b-c427-990308bd4e49"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[8, 9, 8, 5],\n",
              "        [8, 7, 7, 3]])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "s = torch.randint(1, 10, (2, 4))\n",
        "s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J55zS3bWioPf",
        "outputId": "4f95be27-3b2c-4153-c149-46d98897f9d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([2, 1, 1, 4]), torch.Size([2, 1, 4, 4]))"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sm, tm = create_mask(s, s, 5)\n",
        "sm.shape, tm.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIUqWAXDyZyU",
        "outputId": "88d765ec-6fa4-4a73-d84f-b4dbfb7a1281"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[[ True,  True,  True, False]]],\n",
              "\n",
              "\n",
              "        [[[ True,  True,  True,  True]]]])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BO046KwkjOro",
        "outputId": "6fbfde7f-148b-4049-a3a9-eb82704751e9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[[ True, False, False, False],\n",
              "          [ True,  True, False, False],\n",
              "          [ True,  True,  True, False],\n",
              "          [ True,  True,  True, False]]],\n",
              "\n",
              "\n",
              "        [[[ True, False, False, False],\n",
              "          [ True,  True, False, False],\n",
              "          [ True,  True,  True, False],\n",
              "          [ True,  True,  True,  True]]]])"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ux4QKVMh6xjj"
      },
      "outputs": [],
      "source": [
        "pad_token = 0\n",
        "src = torch.tensor([[1, 2, 3, 0], [4, 5, 0, 0]])  # Source sequences with padding\n",
        "tgt = torch.tensor([[1, 2, 0, 0], [4, 5, 6, 0]])  # Target sequences with padding\n",
        "\n",
        "# Create masks\n",
        "src_mask, tgt_mask = create_mask(src, tgt, pad_token)\n",
        "\n",
        "# Instantiate the multi-head attention layer\n",
        "embed_dim = 8\n",
        "n_heads = 2\n",
        "mha = MultiHeadAttention(embed_dim, n_heads)\n",
        "\n",
        "# Example input embeddings (randomly initialized for demonstration)\n",
        "query = torch.randn(2, 4, embed_dim)\n",
        "key = torch.randn(2, 4, embed_dim)\n",
        "value = torch.randn(2, 4, embed_dim)\n",
        "\n",
        "# output = mha(query, key, value, tgt_mask)\n",
        "# print(\"Output:\\n\", output)\n",
        "# print(\"Source Mask:\\n\", src_mask)\n",
        "# print(\"Target Mask:\\n\", tgt_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BI2OJLrB62ga",
        "outputId": "2d22c35e-3c5d-463d-ed58-55e5782ddcfc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([2, 4]), torch.Size([2, 4]))"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "src.shape, tgt.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99JaE8UxSZ6f",
        "outputId": "ce5455a9-f579-419d-a728-e1952ab79f12"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 1, 4, 4])"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tm.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QEPOsAD5BlM",
        "outputId": "57f5e416-0f57-47b5-a1ab-dbbb18ca1f88"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 4, 16])"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "m = MultiHeadAttention(16, 4)\n",
        "q = torch.randn(2, 4, 16)\n",
        "sm, tm = create_mask(src, tgt, 0)\n",
        "m(q, q, q, tm).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_z59uD_IeDv"
      },
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "  def __init__(self, input_vocab, output_vocab, seq_len, embed_dim=512, n_heads=8, num_layers=2, hidden_factor=4, dropout=0.1):\n",
        "    super(Transformer, self).__init__()\n",
        "\n",
        "    self.encoder = Encoder(input_vocab, embed_dim, seq_len, n_heads, num_layers, hidden_factor, dropout)\n",
        "    self.decoder = Decoder(output_vocab, embed_dim, seq_len, n_heads, num_layers, hidden_factor, dropout)\n",
        "\n",
        "  def forward(self, src, tgt, src_mask=None, tgt_mask=None):\n",
        "    enc_output = self.encoder(src)\n",
        "    output = self.decoder.forward(tgt, enc_output, src_mask, tgt_mask)\n",
        "\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EXDUxxCggWn",
        "outputId": "0a779368-9fe7-4a19-bf0d-1e50293c6462"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Transformer(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(5500, 512)\n",
              "    (pe): PositionalEncoding()\n",
              "    (layers): ModuleList(\n",
              "      (0-1): 2 x EncoderLayer(\n",
              "        (self_attn): MultiHeadAttention(\n",
              "          (query_m): Linear(in_features=512, out_features=512, bias=False)\n",
              "          (key_m): Linear(in_features=512, out_features=512, bias=False)\n",
              "          (value_m): Linear(in_features=512, out_features=512, bias=False)\n",
              "          (output): Linear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (feed_fwd): Sequential(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Dropout(p=0.1, inplace=False)\n",
              "          (3): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        )\n",
              "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (drop): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (embedding): Embedding(6000, 512)\n",
              "    (pe): PositionalEncoding()\n",
              "    (layers): ModuleList(\n",
              "      (0-1): 2 x DecoderLayer(\n",
              "        (self_attn): MultiHeadAttention(\n",
              "          (query_m): Linear(in_features=512, out_features=512, bias=False)\n",
              "          (key_m): Linear(in_features=512, out_features=512, bias=False)\n",
              "          (value_m): Linear(in_features=512, out_features=512, bias=False)\n",
              "          (output): Linear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (cross_attn): MultiHeadAttention(\n",
              "          (query_m): Linear(in_features=512, out_features=512, bias=False)\n",
              "          (key_m): Linear(in_features=512, out_features=512, bias=False)\n",
              "          (value_m): Linear(in_features=512, out_features=512, bias=False)\n",
              "          (output): Linear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (feed_fwd): Sequential(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Dropout(p=0.1, inplace=False)\n",
              "          (3): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        )\n",
              "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (drop): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (output): Linear(in_features=512, out_features=6000, bias=True)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tr = Transformer(5500, 6000, 10, 512, 8, 2, 4, 0.1)\n",
        "tr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNU8rG_9g1nT",
        "outputId": "7e5037ae-1292-4722-bfae-93efb0bd40c0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([32, 10, 6000])"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "s = torch.randint(0, 5500, (32, 10))\n",
        "t = torch.randint(0, 6000, (32, 10))\n",
        "sm, tm = create_mask(s, t, 0)\n",
        "tr(s, t, src_mask=None, tgt_mask=tm).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Nprgwx-v42M",
        "outputId": "40bc79de-301b-4e8f-a6f7-643a0e0ef1ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.10/dist-packages (1.8.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pc54rm3vwCE4"
      },
      "outputs": [],
      "source": [
        "import torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ndv9HzmlwE61",
        "outputId": "84039953-6b25-4082-f172-4199d1fa59b4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "======================================================================\n",
              "Layer (type:depth-idx)                        Param #\n",
              "======================================================================\n",
              "Transformer                                   --\n",
              "├─Encoder: 1-1                                --\n",
              "│    └─Embedding: 2-1                         2,816,000\n",
              "│    └─PositionalEncoding: 2-2                --\n",
              "│    └─ModuleList: 2-3                        --\n",
              "│    │    └─EncoderLayer: 3-1                 3,150,848\n",
              "│    │    └─EncoderLayer: 3-2                 3,150,848\n",
              "│    └─Dropout: 2-4                           --\n",
              "├─Decoder: 1-2                                --\n",
              "│    └─Embedding: 2-5                         3,072,000\n",
              "│    └─PositionalEncoding: 2-6                --\n",
              "│    └─ModuleList: 2-7                        --\n",
              "│    │    └─DecoderLayer: 3-3                 4,200,960\n",
              "│    │    └─DecoderLayer: 3-4                 4,200,960\n",
              "│    └─Linear: 2-8                            3,078,000\n",
              "│    └─Dropout: 2-9                           --\n",
              "======================================================================\n",
              "Total params: 23,669,616\n",
              "Trainable params: 23,669,616\n",
              "Non-trainable params: 0\n",
              "======================================================================"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torchinfo.summary(tr)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
