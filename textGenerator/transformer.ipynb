{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('marvel.txt','r',encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I still think about the night\n",
      "your mother and I had to leave you.\n",
      "Hopefully, it's not for long,\n",
      "but I'll call you when we get settled.\n",
      "When I have a better indication of what's going on.\n",
      "Mommy?\n",
      "Jellybean.\n",
      "Daddy and I have a last-minute business trip...\n",
      "so Rose is gonna stay with you for a few days.\n",
      "No. I don't want you to go.\n",
      "Ugh. It's gonna be so boring.\n",
      "I won't be able to keep my...\n",
      "eyes...\n",
      "Goodbye, sweetheart. All right, we'll see you soon.\n",
      "Okay.\n",
      "Janet, we gotta go.\n",
      "I wish we could have put down our bags...\n",
      "tucked you back into your bed...\n",
      "but too many lives were at stake.\n",
      "Oh, my God.\n",
      "They'\n"
     ]
    }
   ],
   "source": [
    "print(text[:600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1147324"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !\"$%&'()*,-./0123456789:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "80\n",
      "[10, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122]\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)\n",
    "print([ord(char) for char in chars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = {ch:i for i,ch in enumerate(chars)}\n",
    "itos = {i:ch for i,ch in enumerate(chars)}\n",
    "encode = lambda s: [stoi[ch] for ch in s]\n",
    "decode = lambda lst: ''.join([itos[i] for i in lst])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I still think about the night\n",
      "your mother and I had to leave you.\n",
      "Hopefully, it's not for long,\n",
      "but \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data = torch.tensor(encode(text),dtype=torch.long,device='cuda')\n",
    "print(decode(data[:100].tolist()))\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I still think about the night\n",
      "your mother and I had to leave you.\n",
      "Hopefully, it's not for long,\n",
      "but \n"
     ]
    }
   ],
   "source": [
    "train_len = int(0.9*len(data))\n",
    "train_data = data[:train_len]\n",
    "val_data = data[train_len:]\n",
    "print(decode(train_data[:100].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 8\n",
    "batch_size = 4\n",
    "n_embd = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[57, 67,  7, 73,  1, 61, 54, 69],\n",
      "        [62, 60, 61, 73,  1, 72, 58, 58],\n",
      "        [72,  1, 69, 74, 73,  1, 68, 67],\n",
      "        [76, 62, 73, 61,  1, 39, 68, 64]], device='cuda:0')\n",
      "tensor([[67,  7, 73,  1, 61, 54, 69, 69],\n",
      "        [60, 61, 73,  1, 72, 58, 58,  1],\n",
      "        [ 1, 69, 74, 73,  1, 68, 67,  1],\n",
      "        [62, 73, 61,  1, 39, 68, 64, 62]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "def get_data(splittype):\n",
    "    data = val_data\n",
    "    if(splittype=='train'): \n",
    "        data = train_data\n",
    "    ix = torch.randint(len(data)-block_size,(batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+1+block_size] for i in ix])\n",
    "    return x,y\n",
    "\n",
    "xb, yb = get_data('train')\n",
    "print(xb)\n",
    "print(yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d->n\n",
      "dn->'\n",
      "dn'->t\n",
      "dn't-> \n",
      "dn't ->h\n",
      "dn't h->a\n",
      "dn't ha->p\n",
      "dn't hap->p\n",
      "i->g\n",
      "ig->h\n",
      "igh->t\n",
      "ight-> \n",
      "ight ->s\n",
      "ight s->e\n",
      "ight se->e\n",
      "ight see-> \n",
      "s-> \n",
      "s ->p\n",
      "s p->u\n",
      "s pu->t\n",
      "s put-> \n",
      "s put ->o\n",
      "s put o->n\n",
      "s put on-> \n",
      "w->i\n",
      "wi->t\n",
      "wit->h\n",
      "with-> \n",
      "with ->L\n",
      "with L->o\n",
      "with Lo->k\n",
      "with Lok->i\n"
     ]
    }
   ],
   "source": [
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context = xb[b,:t+1]\n",
    "        target = yb[b,t]\n",
    "        print(f\"{decode(context.tolist())}->{decode([target.item()])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "o-&!v2FG'1\n",
      "0BBBXQST8-sT\"xj8ucc(SSSiJ-5,DjJV8L'5.M1$f$H)SBDQuNJBJ8lB?SSj)BeCvPztByz Kf.Sj.$x\";!OQrdIS\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd,device=device) \n",
    "        self.positional_embedding_table = nn.Embedding(block_size,n_embd,device=device)\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size,device=device)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "        tok_emb = self.token_embedding_table(idx)  # B x T x C\n",
    "        pos_emb = self.positional_embedding_table(torch.arange(T,device=device))\n",
    "        x = tok_emb + pos_emb\n",
    "        logits = self.lm_head(x)  # B x T x vocab_size\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            C = logits.shape[-1]\n",
    "            logits = logits.view(B * T, C)\n",
    "            targets = targets.view(B * T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits,loss = self(idx[:,-block_size:])\n",
    "            logits = logits[:,-1,:]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "        return idx\n",
    "\n",
    "model = BigramLanguageModel()\n",
    "out = model(xb,yb)\n",
    "print(decode(model.generate(torch.zeros((1,1),device=device,dtype=torch.long),max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "for steps in range(30000):\n",
    "    xb,yb = get_data('train')\n",
    "    logits,loss = model.forward(xb,yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "whin sangot's g houm fu t.\n",
      "Ge hareaprey mo ad undow of TEve.\n",
      "Wan..\n",
      "TEar wime'torry s Plyo mfilitana s mesp ll re in ongong?\n",
      "- is bokerr cateduckigugus iversed.\n",
      "Toupplove?\n",
      "Une. ou.\n",
      "Youn..\n",
      "H l..\n",
      "S: atoureanl wowee ad heinear Gomes.\n",
      "Simy fiaceye s o e p orengos y. g banope.. wasan guristh..\n",
      "Heve g w t tharer St'se worenche hastun the Dit hene tr- l tu teak gal m treat m.\n",
      "Year anghanbore p.\n",
      "Yoiecr hecanat urug smunathout n ofotann. s the y s soffirind! an I INGRURanas...\n",
      "Stho I w s yofominge..\n",
      "Averm\n"
     ]
    }
   ],
   "source": [
    "context = torch.zeros((1,1),dtype=torch.long,device=device)\n",
    "print(decode(model.generate(context,max_new_tokens=500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
